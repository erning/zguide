<?xml version="1.0" encoding="UTF-8" standalone="no"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8" /><title>Multithreading with ØMQ</title><meta name="generator" content="DocBook XSL Stylesheets V1.76.1" /><link rel="home" href="index.html" title="The ZeroMQ Guide - for C Developers" /><link rel="up" href="ch02.html" title="Chapter 2. Sockets and Patterns" /><link rel="prev" href="ch02s05.html" title="Detecting Memory Leaks" /><link rel="next" href="ch02s07.html" title="Signaling Between Threads (PAIR Sockets)" /></head><body><div class="navheader"><table width="100%" summary="Navigation header"><tr><th colspan="3" align="center">Multithreading with ØMQ</th></tr><tr><td width="20%" align="left"><a accesskey="p" href="ch02s05.html">Prev</a> </td><th width="60%" align="center">Chapter 2. Sockets and Patterns</th><td width="20%" align="right"> <a accesskey="n" href="ch02s07.html">Next</a></td></tr></table><hr /></div><div class="sect1" title="Multithreading with ØMQ"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a id="idp19274408"></a>Multithreading with ØMQ</h2></div></div></div><p>ØMQ is perhaps the nicest way ever to write multithreaded (MT) applications. Whereas ØMQ sockets require some readjustment if you are used to traditional sockets, ØMQ multithreading will take everything you know about writing MT applications, throw it into a heap in the garden, pour gasoline over it, and set it alight. It's a rare book that deserves burning, but most books on concurrent programming do.</p><p>To make utterly perfect MT programs (and I mean that literally), <span class="bold"><strong>we don't need mutexes, locks, or any other form of inter-thread communication except messages sent across ØMQ sockets.</strong></span></p><p>By "perfect MT programs", I mean code that's easy to write and understand, that works with the same design approach in any programming language, and on any operating system, and that scales across any number of CPUs with zero wait states and no point of diminishing returns.</p><p>If you've spent years learning tricks to make your MT code work at all, let alone rapidly, with locks and semaphores and critical sections, you will be disgusted when you realize it was all for nothing. If there's one lesson we've learned from 30+ years of concurrent programming, it is: <span class="emphasis"><em>just don't share state</em></span>. It's like two drunkards trying to share a beer. It doesn't matter if they're good buddies. Sooner or later, they're going to get into a fight. And the more drunkards you add to the table, the more they fight each other over the beer. The tragic majority of MT applications look like drunken bar fights.</p><p>The list of weird problems that you need to fight as you write classic shared-state MT code would be hilarious if it didn't translate directly into stress and risk, as code that seems to work suddenly fails under pressure. A large firm with world-beating experience in buggy code released its list of "11 Likely Problems In Your Multithreaded Code", which covers forgotten synchronization, incorrect granularity, read and write tearing, lock-free reordering, lock convoys, two-step dance, and priority inversion.</p><p>Yeah, we counted seven problems, not eleven. That's not the point though. The point is, do you really want that code running the power grid or stock market to start getting two-step lock convoys at 3 p.m. on a busy Thursday? Who cares what the terms actually mean? This is not what turned us on to programming, fighting ever more complex side effects with ever more complex hacks.</p><p>Some widely used models, despite being the basis for entire industries, are fundamentally broken, and shared state concurrency is one of them. Code that wants to scale without limit does it like the Internet does, by sending messages and sharing nothing except a common contempt for broken programming models.</p><p>You should follow some rules to write happy multithreaded code with ØMQ:</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem"><p>Isolate data privately within its thread and never share data in multiple threads. The only exception to this are ØMQ contexts, which are threadsafe.</p></li><li class="listitem"><p>Stay away from the classic concurrency mechanisms like as mutexes, critical sections, semaphores, etc. These are an anti-pattern in ØMQ applications.</p></li><li class="listitem"><p>Create one ØMQ context at the start of your process, and pass that to all threads that you want to connect via <code class="literal">inproc</code> sockets.</p></li><li class="listitem"><p>Use <span class="emphasis"><em>attached</em></span> threads to create structure within your application, and connect these to their parent threads using PAIR sockets over <code class="literal">inproc</code>. The pattern is: bind parent socket, then create child thread which connects its socket.</p></li><li class="listitem"><p>Use <span class="emphasis"><em>detached</em></span> threads to simulate independent tasks, with their own contexts. Connect these over <code class="literal">tcp</code>. Later you can move these to stand-alone processes without changing the code significantly.</p></li><li class="listitem"><p>All interaction between threads happens as ØMQ messages, which you can define more or less formally.</p></li><li class="listitem"><p>Don't share ØMQ sockets between threads. ØMQ sockets are not threadsafe. Technically it's possible to migrate a socket from one thread to another but it demands skill. The only place where it's remotely sane to share sockets between threads are in language bindings that need to do magic like garbage collection on sockets.</p></li></ul></div><p>If you need to start more than one proxy in an application, for example, you will want to run each in their own thread. It is easy to make the error of creating the proxy frontend and backend sockets in one thread, and then passing the sockets to the proxy in another thread. This may appear to work at first but will fail randomly in real use. Remember: <span class="emphasis"><em>Do not use or close sockets except in the thread that created them.</em></span></p><p>If you follow these rules, you can quite easily build elegant multithreaded applications, and later split off threads into separate processes as you need to. Application logic can sit in threads, processes, or nodes: whatever your scale needs.</p><p>ØMQ uses native OS threads rather than virtual "green" threads. The advantage is that you don't need to learn any new threading API, and that ØMQ threads map cleanly to your operating system. You can use standard tools like Intel's ThreadChecker to see what your application is doing. The disadvantages are that native threading APIs are not always portable, and that if you have a huge number of threads (in the thousands), some operating systems will get stressed.</p><p>Let's see how this works in practice. We'll turn our old Hello World server into something more capable. The original server ran in a single thread. If the work per request is low, that's fine: one ØMQ thread can run at full speed on a CPU core, with no waits, doing an awful lot of work. But realistic servers have to do nontrivial work per request. A single core may not be enough when 10,000 clients hit the server all at once. So a realistic server will start multiple worker threads. It then accepts requests as fast as it can and distributes these to its worker threads. The worker threads grind through the work and eventually send their replies back.</p><p>You can, of course, do all this using a proxy broker and external worker processes, but often it's easier to start one process that gobbles up sixteen cores than sixteen processes, each gobbling up one core. Further, running workers as threads will cut out a network hop, latency, and network traffic.</p><p>The MT version of the Hello World service basically collapses the broker and workers into a single process:</p><div class="example"><a id="mtserver-c"></a><p class="title"><strong>Example 2.11. Multithreaded service (mtserver.c)</strong></p><div class="example-contents"><pre class="programlisting">
//  Multithreaded Hello World server

#include "zhelpers.h"
#include &lt;pthread.h&gt;

static void *
worker_routine (void *context) {
    //  Socket to talk to dispatcher
    void *receiver = zmq_socket (context, ZMQ_REP);
    zmq_connect (receiver, "inproc://workers");

    while (1) {
        char *string = s_recv (receiver);
        printf ("Received request: [%s]\n", string);
        free (string);
        //  Do some 'work'
        sleep (1);
        //  Send reply back to client
        s_send (receiver, "World");
    }
    zmq_close (receiver);
    return NULL;
}

int main (void)
{
    void *context = zmq_ctx_new ();

    //  Socket to talk to clients
    void *clients = zmq_socket (context, ZMQ_ROUTER);
    zmq_bind (clients, "tcp://*:5555");

    //  Socket to talk to workers
    void *workers = zmq_socket (context, ZMQ_DEALER);
    zmq_bind (workers, "inproc://workers");

    //  Launch pool of worker threads
    int thread_nbr;
    for (thread_nbr = 0; thread_nbr &lt; 5; thread_nbr++) {
        pthread_t worker;
        pthread_create (&amp;worker, NULL, worker_routine, context);
    }
    //  Connect work threads to client threads via a queue proxy
    zmq_proxy (clients, workers, NULL);

    //  We never get here, but clean up anyhow
    zmq_close (clients);
    zmq_close (workers);
    zmq_ctx_destroy (context);
    return 0;
}
</pre></div></div><br class="example-break" /><div class="figure"><a id="figure-20"></a><p class="title"><strong>Figure 2.12. Multithreaded Server</strong></p><div class="figure-contents"><div class="mediaobject"><img src="images/fig20.png" alt="Multithreaded Server" /></div></div></div><br class="figure-break" /><p>All the code should be recognizable to you by now. How it works:</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem"><p>The server starts a set of worker threads. Each worker thread creates a REP socket and then processes requests on this socket. Worker threads are just like single-threaded servers. The only differences are the transport (<code class="literal">inproc</code> instead of <code class="literal">tcp</code>), and the bind-connect direction.</p></li><li class="listitem"><p>The server creates a ROUTER socket to talk to clients and binds this to its external interface (over <code class="literal">tcp</code>).</p></li><li class="listitem"><p>The server creates a DEALER socket to talk to the workers and binds this to its internal interface (over <code class="literal">inproc</code>).</p></li><li class="listitem"><p>The server starts a proxy that connects the two sockets. The proxy pulls incoming requests fairly from all clients, and distributes those out to workers. It also routes replies back to their origin.</p></li></ul></div><p>Note that creating threads is not portable in most programming languages. The POSIX library is pthreads, but on Windows you have to use a different API. In our example, the <code class="literal">pthread_create</code> call starts up a new thread running the <code class="literal">worker_routine</code> function we defined. We'll see in Advanced Request-Reply Patterns<a class="xref" href="ch03.html" title="Chapter 3. Advanced Request-Reply Patterns">Chapter 3, <em>Advanced Request-Reply Patterns</em></a> how to wrap this in a portable API.</p><p>Here the "work" is just a one-second pause. We could do anything in the workers, including talking to other nodes. This is what the MT server looks like in terms of ØMQ sockets and nodes. Note how the request-reply chain is <code class="literal">REQ-ROUTER-queue-DEALER-REP</code><a class="xref" href="ch02s07.html#figure-21" title="Figure 2.13. The Relay Race">Figure 2.13, “The Relay Race”</a>.</p></div><div class="navfooter"><hr /><table width="100%" summary="Navigation footer"><tr><td width="40%" align="left"><a accesskey="p" href="ch02s05.html">Prev</a> </td><td width="20%" align="center"><a accesskey="u" href="ch02.html">Up</a></td><td width="40%" align="right"> <a accesskey="n" href="ch02s07.html">Next</a></td></tr><tr><td width="40%" align="left" valign="top">Detecting Memory Leaks </td><td width="20%" align="center"><a accesskey="h" href="index.html">Home</a></td><td width="40%" align="right" valign="top"> Signaling Between Threads (PAIR Sockets)</td></tr></table></div></body></html>
